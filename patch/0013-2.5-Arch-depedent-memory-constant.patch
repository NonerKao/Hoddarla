From 35c27f8cd0b7698780eb558f24982a2b01eec3da Mon Sep 17 00:00:00 2001
From: "Alan (Quey-Liang) Kao" <alankao@andestech.com>
Date: Wed, 18 Aug 2021 23:26:14 +0800
Subject: [PATCH 13/20] 2.5 Arch-depedent memory constant

---
 src/runtime/ethanol/early_mm.go | 2 +-
 src/runtime/malloc.go           | 8 +++++---
 src/runtime/mem_opensbi.go      | 2 ++
 3 files changed, 8 insertions(+), 4 deletions(-)

diff --git a/src/runtime/ethanol/early_mm.go b/src/runtime/ethanol/early_mm.go
index 092383e661..55f9c059db 100644
--- a/src/runtime/ethanol/early_mm.go
+++ b/src/runtime/ethanol/early_mm.go
@@ -59,7 +59,7 @@ func MemoryMap(va, pa uintptr, pt pageType) {
 				pt0 := uintptr((NextPageTable+1)*0x1000 + PAGE_TABLE_PA)
 				(*PageTableRoot)[pt1][vpn1] = pt0>>12<<10 | PTE_V
 				vpn0 := (va & 0x00000000001FF000) >> 12
-				(*PageTableRoot)[pt0][vpn0] = pa>>12<<10 | PTE_XWRV
+				(*PageTableRoot)[NextPageTable+1][vpn0] = pa>>12<<10 | PTE_XWRV
 				NextPageTable += 1
 			}
 			return
diff --git a/src/runtime/malloc.go b/src/runtime/malloc.go
index c389cb1e45..93e53121cb 100644
--- a/src/runtime/malloc.go
+++ b/src/runtime/malloc.go
@@ -209,7 +209,7 @@ const (
 	// arenaBaseOffset to offset into the top 4 GiB.
 	//
 	// WebAssembly currently has a limit of 4GB linear memory.
-	heapAddrBits = (_64bit*(1-goarch.IsWasm)*(1-goos.IsIos*goarch.IsArm64))*48 + (1-_64bit+goarch.IsWasm)*(32-(goarch.IsMips+goarch.IsMipsle)) + 33*goos.IsIos*goarch.IsArm64
+	heapAddrBits = (_64bit*(1-goarch.IsWasm)*(1-goos.IsIos*goarch.IsArm64)*(1-goos.IsOpensbi))*48 + (1-_64bit+goarch.IsWasm)*(32-(goarch.IsMips+goarch.IsMipsle)) + 33*goos.IsIos*goarch.IsArm64 + 36*goos.IsOpensbi
 
 	// maxAlloc is the maximum size of an allocation. On 64-bit,
 	// it's theoretically possible to allocate 1<<heapAddrBits bytes. On
@@ -305,7 +305,7 @@ const (
 	//
 	// On other platforms, the user address space is contiguous
 	// and starts at 0, so no offset is necessary.
-	arenaBaseOffset = 0xffff800000000000*goarch.IsAmd64 + 0x0a00000000000000*goos.IsAix
+	arenaBaseOffset = 0xffff800000000000*goarch.IsAmd64 + 0x0a00000000000000*goos.IsAix + 0xffffffc000000000*goos.IsOpensbi
 	// A typed version of this constant that will make it into DWARF (for viewcore).
 	arenaBaseOffsetUintptr = uintptr(arenaBaseOffset)
 
@@ -534,6 +534,8 @@ func mallocinit() {
 				p = uintptr(i)<<40 | uintptrMask&(0x0013<<28)
 			case GOARCH == "arm64":
 				p = uintptr(i)<<40 | uintptrMask&(0x0040<<32)
+			case GOOS == "opensbi":
+				p = uintptr(i)<<26 | uintptr(0xffffffcf00000000)
 			case GOOS == "aix":
 				if i == 0 {
 					// We don't use addresses directly after 0x0A00000000000000
@@ -704,7 +706,7 @@ func (h *mheap) sysAlloc(n uintptr) (v unsafe.Pointer, size uintptr) {
 	}
 
 	// Check for bad pointers or pointers we can't use.
-	{
+	if GOOS != "opensbi" {
 		var bad string
 		p := uintptr(v)
 		if p+size < p {
diff --git a/src/runtime/mem_opensbi.go b/src/runtime/mem_opensbi.go
index 15ebbe2baf..7899991aea 100644
--- a/src/runtime/mem_opensbi.go
+++ b/src/runtime/mem_opensbi.go
@@ -44,6 +44,7 @@ func baseInit() {
 // which prevents us from allocating more stack.
 //go:nosplit
 func sysAlloc(n uintptr, sysStat *sysMemStat) unsafe.Pointer {
+	print("Alloc: ", unsafe.Pointer(n), " bytes \n")
 	p := sysReserve(nil, n)
 	sysMap(p, n, sysStat)
 	return p
@@ -68,6 +69,7 @@ func sysFree(v unsafe.Pointer, n uintptr, sysStat *sysMemStat) {
 func sysFault(v unsafe.Pointer, n uintptr) {
 }
 
+//go:noinline
 func sysReserve(v unsafe.Pointer, n uintptr) unsafe.Pointer {
 	// Let's ignore the v anyway.
 	// Check ethanol/README for memory map.
-- 
2.32.0

